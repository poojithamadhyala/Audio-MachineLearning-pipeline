# ğŸ§ Low-Latency Audio Machine Learning Pipeline

A production-style **audio event classification pipeline** designed for **real-time, low-latency inference**, inspired by on-device audio use cases such as **headphones and smart audio systems**.

This project covers the **entire applied ML lifecycle** â€” from dataset ingestion and model training to ONNX export, latency benchmarking, and API-based inference.

---

## ğŸš€ Key Highlights

- ğŸµ **Audio Event Classification** using MFCC features + lightweight CNN  
- âš¡ **Ultra-low latency inference**: **0.039 ms (batch=1)** via ONNX Runtime  
- ğŸ“Š **~94% test accuracy** on Speech Commands v0.02 dataset  
- ğŸ **Apple MPS backend** used for local training on macOS  
- ğŸ” End-to-end pipeline: training â†’ evaluation â†’ export â†’ deployment  

---

## ğŸ§  Problem Statement

Real-time audio systems (e.g., headphones, wearables, embedded devices) require:
- Extremely **low inference latency**
- Small, efficient models
- Reliable performance under tight compute constraints

This project demonstrates how to design an **ML pipeline optimized for such constraints** while maintaining strong accuracy.

---

## ğŸ—ï¸ Project Architecture


audio-ml-pipeline/
â”œâ”€â”€ src/ # Training, evaluation, ONNX export, benchmarking
â”œâ”€â”€ api/ # FastAPI inference service
â”œâ”€â”€ models/ # Trained model, ONNX export, confusion matrix
â”œâ”€â”€ data/ # Dataset (excluded from repo)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ download_data.py
â””â”€â”€ README.md

---

## ğŸ“Š Model & Performance

- **Model**: MFCC feature extractor + lightweight CNN
- **Classes**: `speech`, `noise`, `silence`
- **Test Accuracy**: ~93.8%
- **ONNX Inference Latency**: **0.039 ms (batch=1)**

Confusion matrix is available in `models/confusion_matrix.png`.

---

## ğŸƒâ€â™‚ï¸ How to Run

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt


